#+OPTIONS: ^:{} _:{} num:t toc:t \n:t
#+include "../../template.org"
#+title:wget下载


* OPTIONS
** -r
   --recursive
   对于HTTP主机，wget首先下载URL指定的文件，然后（如果该文件是一个HTML文档的话）递归下载该文件所引用（超级连接）的所有文件（递归深度由参数-l指定）
   对FTP主机，该参数意味着要下载URL指定的目录中的所有文件，递归方法与HTTP主机类似。
** -l depth
   --level=depth
   指定递归的最大深度
** -k
   --covert-links
   转化文档中的链接为本地链接
** -O file
   --output-document=file
   保存文件名
** -o logfile
   --output-file=logfile
   所有输出信息记录到logfile中
** --limit-rate=amount
   后跟限制下载速度
** -c
   --continue
   续传（下载一个大文件时突然发生中断，可以继续下载）
** -b
   --background
   后台下载，产生wget-log文件显示日志
** --spider
   后跟下载链接用来测试链接是否可用
** -t number
   --tries=number
   指定重试次数
** -T seconds
   --timeout=seconds
   超过seconds则停止
** -q
   --quiet
   关闭输出
** -v
   --verbose
   详细输出，默认
** -i file
   --input-file=file
   下载链接在file文件中
** -B URL
   -base=URL
   基址
** -A acclist
   --accept acclist
** -R rejlist
   --reject reglist
   使用逗号分隔的文件后缀或者通配符列表
** --user=user
** --password=password
   用户名和密码，可以用于ftp和http，--ftp-user=user --ftp-password=password --http-user=user --http-passwor
** -p prefix
   --directory-prefix=prefix
   将下载文件保存在指定prefix中，默认是.即当前目录
** -m
   --mirror
   下载事件网站 wget -m fanhan.tk
** -Y on/off
   -Y on/off即--proxy=on/off 打开或者关闭代理，其中代理可以是环境变量：
#+begin_quote
export PROXY=http://127.0.0.1:8087
#+end_quote
   或者是在~/.wgetrc中:
#+begin_quote
http_proxy = http://127.0.0.1:8087
ftp_proxy = http://127.0.0.1:8087
#+end_quote
   例如我现在用google agent代理下载youtube主页：
#+begin_quote
wget -k -Y on http://www.youtube.com
#+end_quote
* 总结：
** 启动
#+begin_example
-V,  --version           显示wget的版本后退出
-h,  --help              打印语法帮助
-b,  --background        启动后转入后台执行
-e,  --execute=COMMAND   执行`.wgetrc'格式的命令，wgetrc格式参见/etc/wgetrc或~/.wgetrc
#+end_example
** 记录和输入文件
#+begin_example
-o,  --output-file=FILE     把记录写到FILE文件中
-a,  --append-output=FILE   把记录追加到FILE文件中
-d,  --debug                打印调试输出
-q,  --quiet                安静模式(没有输出)
-v,  --verbose              冗长模式(这是缺省设置)
-nv, --non-verbose          关掉冗长模式，但不是安静模式
-i,  --input-file=FILE      下载在FILE文件中出现的URLs
-F,  --force-html           把输入文件当作HTML格式文件对待
-B,  --base=URL             将URL作为在-F -i参数指定的文件中出现的相对链接的前缀
--sslcertfile=FILE     可选客户端证书
--sslcertkey=KEYFILE   可选客户端证书的KEYFILE
--egd-file=FILE        指定EGD socket的文件名
#+end_example
** 下载
#+begin_example
--bind-address=ADDRESS   指定本地使用地址(主机名或IP，当本地有多个IP或名字时使用)
-t,  --tries=NUMBER           设定最大尝试链接次数(0 表示无限制).
-O   --output-document=FILE   把文档写到FILE文件中
-nc, --no-clobber             不要覆盖存在的文件或使用.#前缀
-c,  --continue               接着下载没下载完的文件
--progress=TYPE          设定进程条标记
-N,  --timestamping           不要重新下载文件除非比本地文件新
-S,  --server-response        打印服务器的回应
--spider                 不下载任何东西
-T,  --timeout=SECONDS        设定响应超时的秒数
-w,  --wait=SECONDS           两次尝试之间间隔SECONDS秒
--waitretry=SECONDS      在重新链接之间等待1...SECONDS秒
--random-wait            在下载之间等待0...2*WAIT秒
-Y,  --proxy=on/off           打开或关闭代理
-Q,  --quota=NUMBER           设置下载的容量限制
--limit-rate=RATE        限定下载输率
#+end_example   
** 目录
#+begin_example
-nd  --no-directories            不创建目录
-x,  --force-directories         强制创建目录
-nH, --no-host-directories       不创建主机目录
-P,  --directory-prefix=PREFIX   将文件保存到目录 PREFIX/...
--cut-dirs=NUMBER           忽略 NUMBER层远程目录
#+end_example
** HTTP 选项
#+begin_example
--http-user=USER      设定HTTP用户名为 USER.
--http-passwd=PASS    设定http密码为 PASS.
-C,  --cache=on/off        允许/不允许服务器端的数据缓存 (一般情况下允许).
-E,  --html-extension      将所有text/html文档以.html扩展名保存
--ignore-length       忽略 `Content-Length'头域
--header=STRING       在headers中插入字符串 STRING
--proxy-user=USER     设定代理的用户名为 USER
--proxy-passwd=PASS   设定代理的密码为 PASS
--referer=URL         在HTTP请求中包含 `Referer: URL'头
-s,  --save-headers        保存HTTP头到文件
-U,  --user-agent=AGENT    设定代理的名称为 AGENT而不是 Wget/VERSION.
--no-http-keep-alive  关闭 HTTP活动链接 (永远链接).
--cookies=off         不使用 cookies.
--load-cookies=FILE   在开始会话前从文件 FILE中加载cookie
--save-cookies=FILE   在会话结束后将 cookies保存到 FILE文件中
#+end_example
** FTP 选项
#+begin_example
-nr, --dont-remove-listing   不移走 `.listing'文件
-g,  --glob=on/off           打开或关闭文件名的 globbing机制
--passive-ftp           使用被动传输模式 (缺省值).
--active-ftp            使用主动传输模式
--retr-symlinks         在递归的时候，将链接指向文件(而不是目录)
#+end_example
** 递归下载
#+begin_example
-r,  --recursive          递归下载－－慎用!
-l,  --level=NUMBER       最大递归深度 (inf 或 0 代表无穷).
--delete-after       在现在完毕后局部删除文件
-k,  --convert-links      转换非相对链接为相对链接
-K,  --backup-converted   在转换文件X之前，将之备份为 X.orig
-m,  --mirror             等价于 -r -N -l inf -nr.
-p,  --page-requisites    下载显示HTML文件的所有图片
#+end_example
** 递归下载中的包含和不包含(accept/reject)
#+begin_example
-A,  --accept=LIST                分号分隔的被接受扩展名的列表
-R,  --reject=LIST                分号分隔的不被接受的扩展名的列表
-D,  --domains=LIST               分号分隔的被接受域的列表
--exclude-domains=LIST       分号分隔的不被接受的域的列表
--follow-ftp                 跟踪HTML文档中的FTP链接
--follow-tags=LIST           分号分隔的被跟踪的HTML标签的列表
-G,  --ignore-tags=LIST           分号分隔的被忽略的HTML标签的列表
-H,  --span-hosts                 当递归时转到外部主机
-L,  --relative                   仅仅跟踪相对链接
-I,  --include-directories=LIST   允许目录的列表
-X,  --exclude-directories=LIST   不被包含目录的列表
-np, --no-parent                  不要追溯到父目录
#+end_example
* 例子
** 下载网页
   wget fanhan.tk
   原封不动地下载该网站的index.html，但打开后发现由于路径问题链接的css路径 css/vf.css 不存在所以页面根本没法看，于是我们可以用-k选项将链接转换成适合在本地查看的形式，
   wget -k fanhan.tk
   此时可以看到 css/vf.css转变成了http://fanhan.tk/css/vf.css 于是打开index.html时浏览器会下载该文件以显示页面
** 下载网站
   wget -m fanhan.tk
   把整个网站都下载下来
** 下载文件并重命名
   wget -O emacs.tar.gz http://ftp.gnu.org/gnu/emacs/emacs-24.1.tar.gz
** 下载所有匹配文件
   wget -r -A “*.tar.gz" http://ftp.gnu.org/gnu/emacs
   下载http://ftp.gnu.org/gnu/emacs 目录下的所有以tar.gz结尾的文件
#+BEGIN_HTML
<script src="../../Layout/JS/disqus-comment.js"></script>
<div id="disqus_thread">
</div>
#+END_HTML
